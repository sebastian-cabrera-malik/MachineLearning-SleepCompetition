{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:51:20.676631Z",
     "iopub.status.busy": "2023-11-23T18:51:20.676185Z",
     "iopub.status.idle": "2023-11-23T18:51:24.584660Z",
     "shell.execute_reply": "2023-11-23T18:51:24.583455Z",
     "shell.execute_reply.started": "2023-11-23T18:51:20.676600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:51:24.587880Z",
     "iopub.status.busy": "2023-11-23T18:51:24.586920Z",
     "iopub.status.idle": "2023-11-23T18:51:24.645180Z",
     "shell.execute_reply": "2023-11-23T18:51:24.643823Z",
     "shell.execute_reply.started": "2023-11-23T18:51:24.587844Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas.api.types\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "# These are variables to be used by the score function\n",
    "column_names = {\n",
    "    'series_id_column_name': 'series_id',\n",
    "    'time_column_name': 'step',\n",
    "    'event_column_name': 'event',\n",
    "    'score_column_name': 'score',\n",
    "}\n",
    "\n",
    "tolerances = {\n",
    "    'onset': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360], \n",
    "    'wakeup': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360]\n",
    "}\n",
    "\n",
    "\n",
    "def score(\n",
    "\n",
    "        solution: pd.DataFrame,\n",
    "\n",
    "        submission: pd.DataFrame,\n",
    "\n",
    "        tolerances: Dict[str, List[float]],\n",
    "\n",
    "        series_id_column_name: str,\n",
    "\n",
    "        time_column_name: str,\n",
    "\n",
    "        event_column_name: str,\n",
    "\n",
    "        score_column_name: str,\n",
    "\n",
    "        use_scoring_intervals: bool = False,\n",
    "\n",
    ") -> float:\n",
    "\n",
    "    \"\"\"Event Detection Average Precision, an AUCPR metric for event detection in\n",
    "\n",
    "    time series and video.\n",
    " \n",
    "    This metric is similar to IOU-threshold average precision metrics commonly\n",
    "\n",
    "    used in object detection. For events occuring in time series, we replace the\n",
    "\n",
    "    IOU threshold with a time tolerance.\n",
    " \n",
    "    Submissions are evaluated on the average precision of detected events,\n",
    "\n",
    "    averaged over timestamp error tolerance thresholds, averaged over event\n",
    "\n",
    "    classes.\n",
    " \n",
    "    Detections are matched to ground-truth events within error tolerances, with\n",
    "\n",
    "    ambiguities resolved in order of decreasing confidence.\n",
    " \n",
    "    Detailed Description\n",
    "\n",
    "    --------------------\n",
    "\n",
    "    Evaluation proceeds in four steps:\n",
    " \n",
    "    1. Selection - (optional) Predictions not within a series' scoring\n",
    "\n",
    "    intervals are dropped.\n",
    "\n",
    "    2. Assignment - Predicted events are matched with ground-truth events.\n",
    "\n",
    "    3. Scoring - Each group of predictions is scored against its corresponding\n",
    "\n",
    "    group of ground-truth events via Average Precision.\n",
    "\n",
    "    4. Reduction - The multiple AP scores are averaged to produce a single\n",
    "\n",
    "    overall score.\n",
    " \n",
    "    Selection\n",
    " \n",
    "    With each series there may be a defined set of scoring intervals giving the\n",
    "\n",
    "    intervals of time over which zero or more ground-truth events might be\n",
    "\n",
    "    annotated in that series. A prediction will be evaluated only if it falls\n",
    "\n",
    "    within a scoring interval. These scoring intervals can be chosen to improve\n",
    "\n",
    "    the fairness of evaluation by, for instance, ignoring edge-cases or\n",
    "\n",
    "    ambiguous events.\n",
    " \n",
    "    It is recommended that, if used, scoring intervals be provided for training\n",
    "\n",
    "    data but not test data.\n",
    " \n",
    "    Assignment\n",
    " \n",
    "    For each set of predictions and ground-truths within the same `event x\n",
    "\n",
    "    tolerance x series_id` group, we match each ground-truth to the\n",
    "\n",
    "    highest-confidence unmatched prediction occurring within the allowed\n",
    "\n",
    "    tolerance.\n",
    " \n",
    "    Some ground-truths may not be matched to a prediction and some predictions\n",
    "\n",
    "    may not be matched to a ground-truth. They will still be accounted for in\n",
    "\n",
    "    the scoring, however.\n",
    " \n",
    "    Scoring\n",
    " \n",
    "    Collecting the events within each `series_id`, we compute an Average\n",
    "\n",
    "    Precision score for each `event x tolerance` group. The average precision\n",
    "\n",
    "    score is the area under the (step-wise) precision-recall curve generated by\n",
    "\n",
    "    decreasing confidence score thresholds over the predictions. In this\n",
    "\n",
    "    calculation, matched predictions over the threshold are scored as TP and\n",
    "\n",
    "    unmatched predictions as FP. Unmatched ground-truths are scored as FN.\n",
    " \n",
    "    Reduction\n",
    " \n",
    "    The final score is the average of the above AP scores, first averaged over\n",
    "\n",
    "    tolerance, then over event.\n",
    " \n",
    "    Parameters\n",
    "\n",
    "    ----------\n",
    "\n",
    "    solution : pd.DataFrame, with columns:\n",
    " \n",
    "        `series_id_column_name` identifier for each time series\n",
    " \n",
    "        `time_column_name` the time of occurence for each event as a numeric type\n",
    " \n",
    "        `event_column_name` class label for each event\n",
    " \n",
    "        The solution contains the time of occurence of one or more types of\n",
    "\n",
    "        event within one or more time series. The metric expects the solution to\n",
    "\n",
    "        contain the same event types as those given in `tolerances`.\n",
    " \n",
    "        When `use_scoring_intervals == True`, you may include `start` and `end`\n",
    "\n",
    "        events to delimit intervals within which detections will be scored.\n",
    "\n",
    "        Detected events (from the user submission) outside of these events will\n",
    "\n",
    "        be ignored.\n",
    " \n",
    "    submission : pd.DataFrame, with columns as above and in addition:\n",
    " \n",
    "        `score_column_name` the predicted confidence score for the detected event\n",
    " \n",
    "    tolerances : Dict[str, List[float]]\n",
    " \n",
    "        Maps each event class to a list of timestamp tolerances used\n",
    "\n",
    "        for matching detections to ground-truth events.\n",
    " \n",
    "    use_scoring_intervals: bool, default False\n",
    " \n",
    "        Whether to ignore predicted events outside intervals delimited\n",
    "\n",
    "        by `'start'` and `'end'` events in the solution. When `False`,\n",
    "\n",
    "        the solution should not include `'start'` and `'end'` events.\n",
    "\n",
    "        See the examples for illustration.\n",
    " \n",
    "    Returns\n",
    "\n",
    "    -------\n",
    "\n",
    "    event_detection_ap : float\n",
    "\n",
    "        The mean average precision of the detected events.\n",
    " \n",
    "    Examples\n",
    "\n",
    "    --------\n",
    "\n",
    "    Detecting `'pass'` events in football:\n",
    "\n",
    "    >>> column_names = {\n",
    "\n",
    "    ...     'series_id_column_name': 'video_id',\n",
    "\n",
    "    ...     'time_column_name': 'time',\n",
    "\n",
    "    ...     'event_column_name': 'event',\n",
    "\n",
    "    ...     'score_column_name': 'score',\n",
    "\n",
    "    ... }\n",
    "\n",
    "    >>> tolerances = {'pass': [1.0]}\n",
    "\n",
    "    >>> solution = pd.DataFrame({\n",
    "\n",
    "    ...     'video_id': ['a', 'a'],\n",
    "\n",
    "    ...     'event': ['pass', 'pass'],\n",
    "\n",
    "    ...     'time': [0, 15],\n",
    "\n",
    "    ... })\n",
    "\n",
    "    >>> submission = pd.DataFrame({\n",
    "\n",
    "    ...     'video_id': ['a', 'a', 'a'],\n",
    "\n",
    "    ...     'event': ['pass', 'pass', 'pass'],\n",
    "\n",
    "    ...     'score': [1.0, 0.5, 1.0],\n",
    "\n",
    "    ...     'time': [0, 10, 14.5],\n",
    "\n",
    "    ... })\n",
    "\n",
    "    >>> score(solution, submission, tolerances, **column_names)\n",
    "\n",
    "    1.0\n",
    " \n",
    "    Increasing the confidence score of the false detection above the true\n",
    "\n",
    "    detections decreases the AP.\n",
    "\n",
    "    >>> submission.loc[1, 'score'] = 1.5\n",
    "\n",
    "    >>> score(solution, submission, tolerances, **column_names)\n",
    "\n",
    "    0.6666666666666666...\n",
    " \n",
    "    Likewise, decreasing the confidence score of a true detection below the\n",
    "\n",
    "    false detection also decreases the AP.\n",
    "\n",
    "    >>> submission.loc[1, 'score'] = 0.5  # reset\n",
    "\n",
    "    >>> submission.loc[0, 'score'] = 0.0\n",
    "\n",
    "    >>> score(solution, submission, tolerances, **column_names)\n",
    "\n",
    "    0.8333333333333333...\n",
    " \n",
    "    We average AP scores over tolerances. Previously, the detection at 14.5\n",
    "\n",
    "    would match, but adding smaller tolerances gives AP scores where it does\n",
    "\n",
    "    not match. This results in both a FN, since the ground-truth wasn't\n",
    "\n",
    "    detected, and a FP, since the detected event matches no ground-truth.\n",
    "\n",
    "    >>> tolerances = {'pass': [0.1, 0.2, 1.0]}\n",
    "\n",
    "    >>> score(solution, submission, tolerances, **column_names)\n",
    "\n",
    "    0.3888888888888888...\n",
    " \n",
    "    We also average over time series and over event classes.\n",
    "\n",
    "    >>> tolerances = {'pass': [0.5, 1.0], 'challenge': [0.25, 0.50]}\n",
    "\n",
    "    >>> solution = pd.DataFrame({\n",
    "\n",
    "    ...     'video_id': ['a', 'a', 'b'],\n",
    "\n",
    "    ...     'event': ['pass', 'challenge', 'pass'],\n",
    "\n",
    "    ...     'time': [0, 15, 0],  # restart time for new time series b\n",
    "\n",
    "    ... })\n",
    "\n",
    "    >>> submission = pd.DataFrame({\n",
    "\n",
    "    ...     'video_id': ['a', 'a', 'b'],\n",
    "\n",
    "    ...     'event': ['pass', 'challenge', 'pass'],\n",
    "\n",
    "    ...     'score': [1.0, 0.5, 1.0],\n",
    "\n",
    "    ...     'time': [0, 15, 0],\n",
    "\n",
    "    ... })\n",
    "\n",
    "    >>> score(solution, submission, tolerances, **column_names)\n",
    "\n",
    "    1.0\n",
    " \n",
    "    By adding scoring intervals to the solution, we may choose to ignore\n",
    "\n",
    "    detections outside of those intervals.\n",
    "\n",
    "    >>> tolerances = {'pass': [1.0]}\n",
    "\n",
    "    >>> solution = pd.DataFrame({\n",
    "\n",
    "    ...     'video_id': ['a', 'a', 'a', 'a'],\n",
    "\n",
    "    ...     'event': ['start', 'pass', 'pass', 'end'],\n",
    "\n",
    "    ...     'time': [0, 10, 20, 30],\n",
    "\n",
    "    ... })\n",
    "\n",
    "    >>> submission = pd.DataFrame({\n",
    "\n",
    "    ...     'video_id': ['a', 'a', 'a'],\n",
    "\n",
    "    ...     'event': ['pass', 'pass', 'pass'],\n",
    "\n",
    "    ...     'score': [1.0, 1.0, 1.0],\n",
    "\n",
    "    ...     'time': [10, 20, 40],\n",
    "\n",
    "    ... })\n",
    "\n",
    "    >>> score(solution, submission, tolerances, **column_names, use_scoring_intervals=True)\n",
    "\n",
    "    1.0\n",
    " \n",
    "    \"\"\"\n",
    "\n",
    "    # Validate metric parameters\n",
    "\n",
    "    assert len(tolerances) > 0, \"Events must have defined tolerances.\"\n",
    "\n",
    "    assert set(tolerances.keys()) == set(solution[event_column_name]).difference({'start', 'end'}),        (f\"Solution column {event_column_name} must contain the same events \"\n",
    "\n",
    "         \"as defined in tolerances.\")\n",
    "\n",
    "    assert pd.api.types.is_numeric_dtype(solution[time_column_name]),        f\"Solution column {time_column_name} must be of numeric type.\"\n",
    " \n",
    "    # Validate submission format\n",
    "\n",
    "    for column_name in [\n",
    "\n",
    "        series_id_column_name,\n",
    "\n",
    "        time_column_name,\n",
    "\n",
    "        event_column_name,\n",
    "\n",
    "        score_column_name,\n",
    "\n",
    "    ]:\n",
    "\n",
    "        if column_name not in submission.columns:\n",
    "\n",
    "            raise ParticipantVisibleError(f\"Submission must have column '{target_name}'.\")\n",
    " \n",
    "    if not pd.api.types.is_numeric_dtype(submission[time_column_name]):\n",
    "\n",
    "        raise ParticipantVisibleError(\n",
    "\n",
    "            f\"Submission column '{time_column_name}' must be of numeric type.\"\n",
    "\n",
    "        )\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(submission[score_column_name]):\n",
    "\n",
    "        raise ParticipantVisibleError(\n",
    "\n",
    "            f\"Submission column '{score_column_name}' must be of numeric type.\"\n",
    "\n",
    "        )\n",
    " \n",
    "    # Set these globally to avoid passing around a bunch of arguments\n",
    "\n",
    "    globals()['series_id_column_name'] = series_id_column_name\n",
    "\n",
    "    globals()['time_column_name'] = time_column_name\n",
    "\n",
    "    globals()['event_column_name'] = event_column_name\n",
    "\n",
    "    globals()['score_column_name'] = score_column_name\n",
    "\n",
    "    globals()['use_scoring_intervals'] = use_scoring_intervals\n",
    " \n",
    "    return event_detection_ap(solution, submission, tolerances)\n",
    " \n",
    "def filter_detections(\n",
    "\n",
    "        detections: pd.DataFrame, intervals: pd.DataFrame\n",
    "\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"Drop detections not inside a scoring interval.\"\"\"\n",
    "\n",
    "    detection_time = detections.loc[:, time_column_name].sort_values().to_numpy()\n",
    "\n",
    "    intervals = intervals.to_numpy()\n",
    "\n",
    "    is_scored = np.full_like(detection_time, False, dtype=bool)\n",
    " \n",
    "    i, j = 0, 0\n",
    "\n",
    "    while i < len(detection_time) and j < len(intervals):\n",
    "\n",
    "        time = detection_time[i]\n",
    "\n",
    "        int_ = intervals[j]\n",
    " \n",
    "        # If the detection is prior in time to the interval, go to the next detection.\n",
    "\n",
    "        if time < int_.left:\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        # If the detection is inside the interval, keep it and go to the next detection.\n",
    "\n",
    "        elif time in int_:\n",
    "\n",
    "            is_scored[i] = True\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        # If the detection is later in time, go to the next interval.\n",
    "\n",
    "        else:\n",
    "\n",
    "            j += 1\n",
    " \n",
    "    return detections.loc[is_scored].reset_index(drop=True)\n",
    " \n",
    "def match_detections(\n",
    "\n",
    "        tolerance: float, ground_truths: pd.DataFrame, detections: pd.DataFrame\n",
    "\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"Match detections to ground truth events. Arguments are taken from a common event x tolerance x series_id evaluation group.\"\"\"\n",
    "\n",
    "    detections_sorted = detections.sort_values(score_column_name, ascending=False).dropna()\n",
    "\n",
    "    is_matched = np.full_like(detections_sorted[event_column_name], False, dtype=bool)\n",
    "\n",
    "    gts_matched = set()\n",
    "\n",
    "    for i, det in enumerate(detections_sorted.itertuples(index=False)):\n",
    "\n",
    "        best_error = tolerance\n",
    "\n",
    "        best_gt = None\n",
    " \n",
    "        for gt in ground_truths.itertuples(index=False):\n",
    "\n",
    "            error = abs(getattr(det, time_column_name) - getattr(gt, time_column_name))\n",
    "\n",
    "            if error < best_error and gt not in gts_matched:\n",
    "\n",
    "                best_gt = gt\n",
    "\n",
    "                best_error = error\n",
    " \n",
    "        if best_gt is not None:\n",
    "\n",
    "            is_matched[i] = True\n",
    "\n",
    "            gts_matched.add(best_gt)\n",
    " \n",
    "    detections_sorted['matched'] = is_matched\n",
    " \n",
    "    return detections_sorted\n",
    " \n",
    "\n",
    "def precision_recall_curve(\n",
    "\n",
    "        matches: np.ndarray, scores: np.ndarray, p: int\n",
    "\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "\n",
    "    if len(matches) == 0:\n",
    "\n",
    "        return [1], [0], []\n",
    " \n",
    "    # Sort matches by decreasing confidence\n",
    "\n",
    "    idxs = np.argsort(scores, kind='stable')[::-1]\n",
    "\n",
    "    scores = scores[idxs]\n",
    "\n",
    "    matches = matches[idxs]\n",
    " \n",
    "    distinct_value_indices = np.where(np.diff(scores))[0]\n",
    "\n",
    "    threshold_idxs = np.r_[distinct_value_indices, matches.size - 1]\n",
    "\n",
    "    thresholds = scores[threshold_idxs]\n",
    " \n",
    "    # Matches become TPs and non-matches FPs as confidence threshold decreases\n",
    "\n",
    "    tps = np.cumsum(matches)[threshold_idxs]\n",
    "\n",
    "    fps = np.cumsum(~matches)[threshold_idxs]\n",
    " \n",
    "    precision = tps / (tps + fps)\n",
    "\n",
    "    precision[np.isnan(precision)] = 0\n",
    "\n",
    "    recall = tps / p  # total number of ground truths might be different than total number of matches\n",
    " \n",
    "    # Stop when full recall attained and reverse the outputs so recall is non-increasing.\n",
    "\n",
    "    last_ind = tps.searchsorted(tps[-1])\n",
    "\n",
    "    sl = slice(last_ind, None, -1)\n",
    " \n",
    "    # Final precision is 1 and final recall is 0\n",
    "\n",
    "    return np.r_[precision[sl], 1], np.r_[recall[sl], 0], thresholds[sl]\n",
    " \n",
    "\n",
    "def average_precision_score(matches: np.ndarray, scores: np.ndarray, p: int) -> float:\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(matches, scores, p)\n",
    "\n",
    "    # Compute step integral\n",
    "\n",
    "    return -np.sum(np.diff(recall) * np.array(precision)[:-1])\n",
    " \n",
    "\n",
    "def event_detection_ap(\n",
    "\n",
    "        solution: pd.DataFrame,\n",
    "\n",
    "        submission: pd.DataFrame,\n",
    "\n",
    "        tolerances: Dict[str, List[float]],\n",
    "\n",
    ") -> float:\n",
    " \n",
    "    # Ensure solution and submission are sorted properly\n",
    "\n",
    "    solution = solution.sort_values([series_id_column_name, time_column_name])\n",
    "\n",
    "    submission = submission.sort_values([series_id_column_name, time_column_name])\n",
    " \n",
    "    # Extract scoring intervals.\n",
    "\n",
    "    if use_scoring_intervals:\n",
    "\n",
    "        intervals = (\n",
    "\n",
    "            solution\n",
    "\n",
    "            .query(\"event in ['start', 'end']\")\n",
    "\n",
    "            .assign(interval=lambda x: x.groupby([series_id_column_name, event_column_name]).cumcount())\n",
    "\n",
    "            .pivot(\n",
    "\n",
    "                index='interval',\n",
    "\n",
    "                columns=[series_id_column_name, event_column_name],\n",
    "\n",
    "                values=time_column_name,\n",
    "\n",
    "            )\n",
    "\n",
    "            .stack(series_id_column_name)\n",
    "\n",
    "            .swaplevel()\n",
    "\n",
    "            .sort_index()\n",
    "\n",
    "            .loc[:, ['start', 'end']]\n",
    "\n",
    "            .apply(lambda x: pd.Interval(*x, closed='both'), axis=1)\n",
    "\n",
    "        )\n",
    " \n",
    "    # Extract ground-truth events.\n",
    "\n",
    "    ground_truths = (\n",
    "\n",
    "        solution\n",
    "\n",
    "        .query(\"event not in ['start', 'end']\")\n",
    "\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    " \n",
    "    # Map each event class to its prevalence (needed for recall calculation)\n",
    "\n",
    "    class_counts = ground_truths.value_counts(event_column_name).to_dict()\n",
    " \n",
    "    # Create table for detections with a column indicating a match to a ground-truth event\n",
    "\n",
    "    detections = submission.assign(matched = False)\n",
    " \n",
    "    # Remove detections outside of scoring intervals\n",
    "\n",
    "    if use_scoring_intervals:\n",
    "\n",
    "        detections_filtered = []\n",
    "\n",
    "        for (det_group, dets), (int_group, ints) in zip(\n",
    "\n",
    "            detections.groupby(series_id_column_name), intervals.groupby(series_id_column_name)\n",
    "\n",
    "        ):\n",
    "\n",
    "            assert det_group == int_group\n",
    "\n",
    "            detections_filtered.append(filter_detections(dets, ints))\n",
    "\n",
    "        detections_filtered = pd.concat(detections_filtered, ignore_index=True)\n",
    "\n",
    "    else:\n",
    "\n",
    "        detections_filtered = detections\n",
    " \n",
    "    # Create table of event-class x tolerance x series_id values\n",
    "\n",
    "    aggregation_keys = pd.DataFrame(\n",
    "\n",
    "        [(ev, tol, vid)\n",
    "\n",
    "         for ev in tolerances.keys()\n",
    "\n",
    "         for tol in tolerances[ev]\n",
    "\n",
    "         for vid in ground_truths[series_id_column_name].unique()],\n",
    "\n",
    "        columns=[event_column_name, 'tolerance', series_id_column_name],\n",
    "\n",
    "    )\n",
    " \n",
    "    # Create match evaluation groups: event-class x tolerance x series_id\n",
    "\n",
    "    detections_grouped = (\n",
    "\n",
    "        aggregation_keys\n",
    "\n",
    "        .merge(detections_filtered, on=[event_column_name, series_id_column_name], how='left')\n",
    "\n",
    "        .groupby([event_column_name, 'tolerance', series_id_column_name])\n",
    "\n",
    "    )\n",
    "\n",
    "    ground_truths_grouped = (\n",
    "\n",
    "        aggregation_keys\n",
    "\n",
    "        .merge(ground_truths, on=[event_column_name, series_id_column_name], how='left')\n",
    "\n",
    "        .groupby([event_column_name, 'tolerance', series_id_column_name])\n",
    "\n",
    "    )\n",
    "\n",
    "    # Match detections to ground truth events by evaluation group\n",
    "\n",
    "    detections_matched = []\n",
    "\n",
    "    for key in aggregation_keys.itertuples(index=False):\n",
    "\n",
    "        dets = detections_grouped.get_group(key)\n",
    "\n",
    "        gts = ground_truths_grouped.get_group(key)\n",
    "\n",
    "        detections_matched.append(\n",
    "\n",
    "            match_detections(dets['tolerance'].iloc[0], gts, dets)\n",
    "\n",
    "        )\n",
    "\n",
    "    detections_matched = pd.concat(detections_matched)\n",
    " \n",
    "    # Compute AP per event x tolerance group\n",
    "\n",
    "    event_classes = ground_truths[event_column_name].unique()\n",
    "\n",
    "    ap_table = (\n",
    "\n",
    "        detections_matched\n",
    "\n",
    "        .query(\"event in @event_classes\")\n",
    "\n",
    "        .groupby([event_column_name, 'tolerance']).apply(\n",
    "\n",
    "            lambda group: average_precision_score(\n",
    "\n",
    "                group['matched'].to_numpy(),\n",
    "\n",
    "                group[score_column_name].to_numpy(),\n",
    "\n",
    "                class_counts[group[event_column_name].iat[0]],\n",
    "\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "    )\n",
    "\n",
    "    # Average over tolerances, then over event classes\n",
    "\n",
    "    mean_ap = ap_table.groupby(event_column_name).mean().sum() / len(event_classes)\n",
    " \n",
    "    return mean_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:51:40.823819Z",
     "iopub.status.busy": "2023-11-23T18:51:40.823337Z",
     "iopub.status.idle": "2023-11-23T18:51:42.042867Z",
     "shell.execute_reply": "2023-11-23T18:51:42.041655Z",
     "shell.execute_reply.started": "2023-11-23T18:51:40.823777Z"
    }
   },
   "outputs": [],
   "source": [
    "file='/kaggle/input/gammaa-train-test-validation-series/train_set_with_variables.parquet'\n",
    "train  = pd.read_parquet(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:51:43.444141Z",
     "iopub.status.busy": "2023-11-23T18:51:43.443760Z",
     "iopub.status.idle": "2023-11-23T18:52:02.717547Z",
     "shell.execute_reply": "2023-11-23T18:52:02.716508Z",
     "shell.execute_reply.started": "2023-11-23T18:51:43.444114Z"
    }
   },
   "outputs": [],
   "source": [
    "file = '/kaggle/input/gammaa-train-test-validation-series/test_set_with_variables.parquet'\n",
    "test  = pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:52:13.923406Z",
     "iopub.status.busy": "2023-11-23T18:52:13.922973Z",
     "iopub.status.idle": "2023-11-23T18:52:36.910336Z",
     "shell.execute_reply": "2023-11-23T18:52:36.909388Z",
     "shell.execute_reply.started": "2023-11-23T18:52:13.923372Z"
    }
   },
   "outputs": [],
   "source": [
    "file = '/kaggle/input/gammaa-train-test-validation-series/validation_set_with_variables.parquet'\n",
    "val  = pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:43:38.592140Z",
     "iopub.status.busy": "2023-11-21T21:43:38.591727Z",
     "iopub.status.idle": "2023-11-21T21:43:38.626130Z",
     "shell.execute_reply": "2023-11-21T21:43:38.624874Z",
     "shell.execute_reply.started": "2023-11-21T21:43:38.592111Z"
    }
   },
   "outputs": [],
   "source": [
    "val.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:52:36.912955Z",
     "iopub.status.busy": "2023-11-23T18:52:36.912349Z",
     "iopub.status.idle": "2023-11-23T18:53:02.495024Z",
     "shell.execute_reply": "2023-11-23T18:53:02.493958Z",
     "shell.execute_reply.started": "2023-11-23T18:52:36.912921Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=['series_id', 'timestamp'])\n",
    "val = val.sort_values(by=['series_id', 'timestamp'])\n",
    "test = test.sort_values(by=['series_id', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:12:10.483320Z",
     "iopub.status.busy": "2023-11-23T15:12:10.482886Z",
     "iopub.status.idle": "2023-11-23T15:12:14.492379Z",
     "shell.execute_reply": "2023-11-23T15:12:14.491418Z",
     "shell.execute_reply.started": "2023-11-23T15:12:10.483287Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[train['event']=='onset','event'] = 0\n",
    "train.loc[train['event']=='wakeup','event'] = 1\n",
    "\n",
    "val.loc[val['event']=='onset','event'] = 0\n",
    "val.loc[val['event']=='wakeup','event'] = 1\n",
    "\n",
    "test.loc[test['event']=='onset','event'] = 0\n",
    "test.loc[test['event']=='wakeup','event'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:44:28.047973Z",
     "iopub.status.busy": "2023-11-21T23:44:28.047588Z",
     "iopub.status.idle": "2023-11-21T23:44:29.681970Z",
     "shell.execute_reply": "2023-11-21T23:44:29.681118Z",
     "shell.execute_reply.started": "2023-11-21T23:44:28.047945Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize data \n",
    "\n",
    "train['anglez'] = train['anglez'] / max(abs(max(train['anglez'])),abs(min(train['anglez'])))\n",
    "train['enmo'] = train['enmo'] / max(abs(max(train['enmo'])),abs(min(train['enmo'])))\n",
    "\n",
    "val['anglez'] = val['anglez'] / max(abs(max(val['anglez'])),abs(min(val['anglez'])))\n",
    "val['enmo'] = val['enmo'] / max(abs(max(val['enmo'])),abs(min(val['enmo'])))\n",
    "\n",
    "test['anglez'] = test['anglez'] / max(abs(max(test['anglez'])),abs(min(test['anglez'])))\n",
    "test['enmo'] = test['enmo'] / max(abs(max(test['enmo'])),abs(min(test['enmo'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:12:32.026902Z",
     "iopub.status.busy": "2023-11-23T15:12:32.026419Z",
     "iopub.status.idle": "2023-11-23T15:12:33.567051Z",
     "shell.execute_reply": "2023-11-23T15:12:33.565838Z",
     "shell.execute_reply.started": "2023-11-23T15:12:32.026863Z"
    }
   },
   "outputs": [],
   "source": [
    "# get unique individual  \n",
    "series_id_train = train['series_id'].unique()\n",
    "series_id_val = val['series_id'].unique()\n",
    "series_id_test = test['series_id'].unique()\n",
    "\n",
    "print('number of series in train:',len(series_id_train))\n",
    "print('number of series in validation:',len(series_id_val))\n",
    "print('number of series in test:',len(series_id_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:12:40.170117Z",
     "iopub.status.busy": "2023-11-23T15:12:40.169718Z",
     "iopub.status.idle": "2023-11-23T15:12:40.176191Z",
     "shell.execute_reply": "2023-11-23T15:12:40.174786Z",
     "shell.execute_reply.started": "2023-11-23T15:12:40.170086Z"
    }
   },
   "outputs": [],
   "source": [
    "#randomly select individual from dataset \n",
    "\n",
    "idx_train = random.choices(series_id_train, k = 100 )\n",
    "idx_val = random.choices(series_id_val, k = 20)\n",
    "#idx_test = random.choices(series_id_test, k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:12:57.441816Z",
     "iopub.status.busy": "2023-11-23T15:12:57.440988Z",
     "iopub.status.idle": "2023-11-23T15:13:06.143879Z",
     "shell.execute_reply": "2023-11-23T15:13:06.142855Z",
     "shell.execute_reply.started": "2023-11-23T15:12:57.441781Z"
    }
   },
   "outputs": [],
   "source": [
    "# select data \n",
    "\n",
    "cols = ['series_id', 'timestamp', 'step', 'anglez', 'enmo', 'event' ]\n",
    "\n",
    "# Split data into input and output sequences\n",
    "x_train = train.loc[train['series_id'].isin(idx_train)][['anglez','enmo']]\n",
    "y_train = train.loc[train['series_id'].isin(idx_train)][['event']]\n",
    "\n",
    "x_val = val.loc[val['series_id'].isin(idx_val)][['anglez', 'enmo']]\n",
    "y_val = val.loc[val['series_id'].isin(idx_val)][['event']]\n",
    "\n",
    "#x_test = test.loc[test['series_id'].isin(idx_test)][['anglez', 'enmo']]\n",
    "#y_test = test.loc[test['series_id'].isin(idx_test)][['event']]\n",
    "\n",
    "x_test_graph = test.loc[test['series_id'].isin(series_id_test)][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T21:05:29.315997Z",
     "iopub.status.busy": "2023-11-22T21:05:29.314565Z",
     "iopub.status.idle": "2023-11-22T21:05:45.269497Z",
     "shell.execute_reply": "2023-11-22T21:05:45.268230Z",
     "shell.execute_reply.started": "2023-11-22T21:05:29.315944Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:13:13.077408Z",
     "iopub.status.busy": "2023-11-23T15:13:13.077031Z",
     "iopub.status.idle": "2023-11-23T15:13:30.089121Z",
     "shell.execute_reply": "2023-11-23T15:13:30.087758Z",
     "shell.execute_reply.started": "2023-11-23T15:13:13.077379Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to torch\n",
    "x_train = x_train.values.tolist()\n",
    "y_train = y_train.values.tolist()\n",
    "\n",
    "x_val = x_val.values.tolist()\n",
    "y_val = y_val.values.tolist()\n",
    "\n",
    "#x_test = x_test.values.tolist()\n",
    "#y_test = y_test.values.tolist()\n",
    "\n",
    "x_train = torch.tensor(x_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "x_val = torch.tensor(x_val)\n",
    "y_val = torch.tensor(y_val)\n",
    "\n",
    "#x_test = torch.tensor(x_test)\n",
    "#y_test = torch.tensor(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "#print(x_test.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:13:35.143375Z",
     "iopub.status.busy": "2023-11-23T15:13:35.142536Z",
     "iopub.status.idle": "2023-11-23T15:13:35.149343Z",
     "shell.execute_reply": "2023-11-23T15:13:35.148111Z",
     "shell.execute_reply.started": "2023-11-23T15:13:35.143336Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class dataset(Dataset):\n",
    "  def __init__(self, x, y):\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.x[index], self.y[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:13:42.512103Z",
     "iopub.status.busy": "2023-11-23T15:13:42.511725Z",
     "iopub.status.idle": "2023-11-23T15:13:42.517389Z",
     "shell.execute_reply": "2023-11-23T15:13:42.515963Z",
     "shell.execute_reply.started": "2023-11-23T15:13:42.512074Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset(x_train, y_train)\n",
    "val_dataset = dataset(x_val, y_val)\n",
    "#test_dataset = dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:13:46.781704Z",
     "iopub.status.busy": "2023-11-23T15:13:46.781312Z",
     "iopub.status.idle": "2023-11-23T15:13:46.787937Z",
     "shell.execute_reply": "2023-11-23T15:13:46.786612Z",
     "shell.execute_reply.started": "2023-11-23T15:13:46.781671Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 100 )\n",
    "val_loader = DataLoader(val_dataset, batch_size = 100)\n",
    "#test_loader = DataLoader(test_dataset, batch_size = 40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:13:51.254934Z",
     "iopub.status.busy": "2023-11-23T15:13:51.254422Z",
     "iopub.status.idle": "2023-11-23T15:13:51.262088Z",
     "shell.execute_reply": "2023-11-23T15:13:51.260940Z",
     "shell.execute_reply.started": "2023-11-23T15:13:51.254783Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "#print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:14:10.970535Z",
     "iopub.status.busy": "2023-11-23T15:14:10.970136Z",
     "iopub.status.idle": "2023-11-23T15:14:10.978333Z",
     "shell.execute_reply": "2023-11-23T15:14:10.977279Z",
     "shell.execute_reply.started": "2023-11-23T15:14:10.970502Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class RNN_Cell(nn.Module): \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \n",
    "        super(RNN_Cell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # we randomly initialize our trainable parameters\n",
    "        self.U = torch.nn.Parameter(torch.randn(input_size, hidden_size))\n",
    "        self.W = torch.nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        self.b = torch.nn.Parameter(torch.randn(hidden_size))\n",
    "\n",
    "    def forward(self, x, state):\n",
    "\n",
    "        h_prev = state\n",
    "\n",
    "        a = torch.mm(x, self.U) + torch.mm(h_prev, self.W) + self.b\n",
    "        #h = torch.sigmoid(a)\n",
    "        h = torch.tanh(a)\n",
    "        #print('h shape',h.shape)    \n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T15:14:18.896672Z",
     "iopub.status.busy": "2023-11-23T15:14:18.896246Z",
     "iopub.status.idle": "2023-11-23T15:14:18.905174Z",
     "shell.execute_reply": "2023-11-23T15:14:18.903556Z",
     "shell.execute_reply.started": "2023-11-23T15:14:18.896637Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn_cell = RNN_Cell(input_dim, hidden_size)\n",
    "        # here is the missing equation from before, \n",
    "        # in Torch the feed-forward layers are called Linear\n",
    "        self.linear = nn.Linear(hidden_size, 1) \n",
    "        #self.sigmoid = nn.Linear(self.linear)\n",
    "        \n",
    "    def init_hidden(self,):\n",
    "        return torch.zeros(1,self.hidden_size) #we initialize our hidden state with zeros\n",
    "    \n",
    "    def forward(self, X, h):\n",
    "        \n",
    "        self.h = h\n",
    "        #print('h', h.shape)\n",
    "        outputs = []\n",
    "\n",
    "        # we will process the sequence here\n",
    "        for X_t in X:\n",
    "            #print(\"X_t shape\", X_t.shape)\n",
    "            self.h = self.rnn_cell.forward(X_t, self.h)\n",
    "            #print('h shape', h.shape)\n",
    "            \n",
    "            y_t = self.linear.forward(self.h)\n",
    "            \n",
    "            y_t = torch.sigmoid(y_t)\n",
    "           \n",
    "            outputs.append(y_t)\n",
    "\n",
    "        return torch.stack(outputs), self.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T17:50:34.126397Z",
     "iopub.status.busy": "2023-11-22T17:50:34.125523Z",
     "iopub.status.idle": "2023-11-22T20:06:53.365446Z",
     "shell.execute_reply": "2023-11-22T20:06:53.362439Z",
     "shell.execute_reply.started": "2023-11-22T17:50:34.126354Z"
    }
   },
   "outputs": [],
   "source": [
    "# valiation to find best hidden unit\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.01\n",
    "input_size = 2\n",
    "hidden_sizes = [10, 20, 30, 40]\n",
    "#hidden_sizes = [40]\n",
    "output_size = 1\n",
    "\n",
    "hs = []\n",
    "accuracies = []\n",
    "\n",
    "for hidden_size in hidden_sizes: \n",
    "    \n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    losses = []\n",
    "    \n",
    "    # Create an instance of the RNN model\n",
    "    model = RNN(input_size, hidden_size)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    h = model.init_hidden()\n",
    "    \n",
    "    # Set number of epochs\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "                \n",
    "        #losses = []\n",
    "        \n",
    "        model.train()\n",
    "        for bx,by in train_loader: \n",
    "            bx, by, model = bx.to(device), by.to(device), model.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output,h = model(bx.float().view(-1,1,2),h) \n",
    "            \n",
    "            loss = criterion(output.view(-1), by.float().view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            h.detach_()\n",
    "        \n",
    "              \n",
    "        model.eval()\n",
    "        for bx, by in val_loader:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "    \n",
    "                y_prob, h = model(bx.float().view(-1,1,2), h)\n",
    "\n",
    "            y_pred = torch.where(y_prob > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "    \n",
    "            correct += torch.sum(torch.squeeze(y_pred) == torch.squeeze(by))\n",
    "    \n",
    "    \n",
    "            total += len(by)\n",
    "     \n",
    "        accuracy = correct/total\n",
    "       \n",
    "        \n",
    "    hs.append(hidden_size)\n",
    "    accuracies.append(accuracy)  \n",
    "    \n",
    "        \n",
    "           \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T20:06:59.705296Z",
     "iopub.status.busy": "2023-11-22T20:06:59.704783Z",
     "iopub.status.idle": "2023-11-22T20:06:59.715752Z",
     "shell.execute_reply": "2023-11-22T20:06:59.714829Z",
     "shell.execute_reply.started": "2023-11-22T20:06:59.705259Z"
    }
   },
   "outputs": [],
   "source": [
    "print(hs)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train model with best hidden size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:51:12.366457Z",
     "iopub.status.busy": "2023-11-23T18:51:12.366081Z",
     "iopub.status.idle": "2023-11-23T18:51:12.408762Z",
     "shell.execute_reply": "2023-11-23T18:51:12.406998Z",
     "shell.execute_reply.started": "2023-11-23T18:51:12.366428Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the RNN model with h = 20\n",
    "lr = 0.01\n",
    "input_size = 2\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = RNN(input_size, hidden_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=0.01)\n",
    "\n",
    "h = model.init_hidden()\n",
    "\n",
    "# Set number of epochs\n",
    "num_epochs = 100\n",
    "accuracy = 0\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "                \n",
    "        losses = []\n",
    "        model.train()\n",
    "        for bx,by in train_loader: \n",
    "            bx, by, model = bx.to(device), by.to(device), model.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output,h = model(bx.float().view(-1,1,2),h) \n",
    "            loss = criterion(output.view(-1), by.float().view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            h.detach_()\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "            print('loss:',np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T16:33:46.662131Z",
     "iopub.status.busy": "2023-11-23T16:33:46.661707Z",
     "iopub.status.idle": "2023-11-23T16:42:28.295585Z",
     "shell.execute_reply": "2023-11-23T16:42:28.294417Z",
     "shell.execute_reply.started": "2023-11-23T16:33:46.662090Z"
    }
   },
   "outputs": [],
   "source": [
    "tests = []\n",
    "\n",
    "with torch.no_grad():\n",
    "   \n",
    "    for name, group in x_test_graph.groupby('series_id'):\n",
    "   \n",
    "        group['timestamp'] = pd.to_datetime(group['timestamp'])\n",
    "    \n",
    "        x = group[['anglez', 'enmo']]\n",
    "        y = group[['event']]\n",
    "        x = x.values.tolist()\n",
    "        y = y.values.tolist()\n",
    "        x = torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        \n",
    "        y_prob, h = model(x.float().view(-1,1,2), h)\n",
    "        \n",
    "        y_pred = torch.where(y_prob > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "        \n",
    "        group['prediction'] = torch.squeeze(y_pred)\n",
    "        \n",
    "        group['prob'] = torch.squeeze(y_prob)\n",
    "        \n",
    "        group['score'] = group['prob'].rolling(60*12*5, center=True, min_periods=10).mean().bfill().ffill()\n",
    "        \n",
    "        group['prediction'] = group['prediction'].rolling(360+1, center=True).median()\n",
    "        \n",
    "        group.loc[group['prediction']==0, 'prob'] = 1-group.loc[group['prediction']==0, 'prob']\n",
    "        \n",
    "        group['pred_diff'] = group['prediction'].diff()\n",
    "        \n",
    "        group = group.drop(columns='event')\n",
    "        \n",
    "        group['event'] = group['pred_diff'].replace({1:'wakeup', -1:'onset', 0:np.nan})\n",
    "    \n",
    "        test_wakeup = group[group['event']=='wakeup'].groupby(group['timestamp'].dt.date).agg('first')\n",
    "        test_onset = group[group['event']=='onset'].groupby(group['timestamp'].dt.date).agg('last')\n",
    "    \n",
    "        group = pd.concat([test_wakeup, test_onset], ignore_index=True).sort_values('timestamp')\n",
    "        \n",
    "        tests.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T17:09:03.740070Z",
     "iopub.status.busy": "2023-11-23T17:09:03.739470Z",
     "iopub.status.idle": "2023-11-23T17:09:03.760184Z",
     "shell.execute_reply": "2023-11-23T17:09:03.759100Z",
     "shell.execute_reply.started": "2023-11-23T17:09:03.740012Z"
    }
   },
   "outputs": [],
   "source": [
    "events_submission = pd.concat(tests, ignore_index=True).reset_index(names='row_id')\n",
    "len(events_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T17:09:23.630407Z",
     "iopub.status.busy": "2023-11-23T17:09:23.628880Z",
     "iopub.status.idle": "2023-11-23T17:09:23.660287Z",
     "shell.execute_reply": "2023-11-23T17:09:23.659437Z",
     "shell.execute_reply.started": "2023-11-23T17:09:23.630370Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import polars as pl\n",
    "train_events = (pl.scan_csv('/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv')\n",
    "                .with_columns(\n",
    "                    (\n",
    "                        (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\")),\n",
    "                        (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\").dt.year().alias(\"year\")),\n",
    "                        (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\").dt.month().alias(\"month\")),\n",
    "                        (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\").dt.day().alias(\"day\")),\n",
    "                        (pl.col(\"timestamp\").str.strptime(pl.Datetime, \"%Y-%m-%dT%H:%M:%S%Z\").dt.hour().alias(\"hour\")),\n",
    "                    )\n",
    "                )\n",
    "                .collect()\n",
    "                .to_pandas()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T17:09:25.974979Z",
     "iopub.status.busy": "2023-11-23T17:09:25.974129Z",
     "iopub.status.idle": "2023-11-23T17:09:35.063559Z",
     "shell.execute_reply": "2023-11-23T17:09:35.062162Z",
     "shell.execute_reply.started": "2023-11-23T17:09:25.974942Z"
    }
   },
   "outputs": [],
   "source": [
    "val_solution = train_events[train_events['series_id'].isin(series_id_test)][['series_id', 'event', 'step']]\n",
    "#val_solution = train_events[train_events['series_id'].isin(series_id_test2)][['series_id', 'event', 'step']]\n",
    "val_solution = val_solution[val_solution['step'].notna()]\n",
    "val_solution = val_solution.reset_index(drop=True)\n",
    "val_solution = val_solution.reset_index().rename(columns={'index': 'row_id'})\n",
    "\n",
    "#xgb_submission=xgb_submission[(xgb_submission['score']>0.1)]\n",
    "\n",
    "#for the weird case\n",
    "#print(f\"Model score: {score(val_solution, events_submission[(events_submission['row_id']<26)],tolerances, **column_names)}\")\n",
    "print(f\"Model score: {score(val_solution, events_submission,tolerances, **column_names)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T17:09:55.553750Z",
     "iopub.status.busy": "2023-11-23T17:09:55.552590Z",
     "iopub.status.idle": "2023-11-23T17:10:15.882858Z",
     "shell.execute_reply": "2023-11-23T17:10:15.881746Z",
     "shell.execute_reply.started": "2023-11-23T17:09:55.553699Z"
    }
   },
   "outputs": [],
   "source": [
    "#for i in series_id_test2:\n",
    "ser_ids = []\n",
    "score_ids = []\n",
    "\n",
    "for i in series_id_test:\n",
    "    ser_ids.append(i)\n",
    "    score_ids.append(score(val_solution[(val_solution['series_id']==i)],events_submission[(events_submission['series_id']==i)],tolerances, **column_names))\n",
    "    print(f\"Model score - {i} : {score(val_solution[(val_solution['series_id']==i)],events_submission[(events_submission['series_id']==i)],tolerances, **column_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T16:33:30.942820Z",
     "iopub.status.busy": "2023-11-23T16:33:30.942132Z",
     "iopub.status.idle": "2023-11-23T16:33:30.949043Z",
     "shell.execute_reply": "2023-11-23T16:33:30.947718Z",
     "shell.execute_reply.started": "2023-11-23T16:33:30.942780Z"
    }
   },
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame({'series_id': ser_ids,\n",
    "            'score': score_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T17:10:22.012804Z",
     "iopub.status.busy": "2023-11-23T17:10:22.012397Z",
     "iopub.status.idle": "2023-11-23T17:10:22.030259Z",
     "shell.execute_reply": "2023-11-23T17:10:22.029299Z",
     "shell.execute_reply.started": "2023-11-23T17:10:22.012771Z"
    }
   },
   "outputs": [],
   "source": [
    "score_df.to_csv('score.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "datasetId": 3970340,
     "sourceId": 6913417,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3975890,
     "sourceId": 6924277,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3975914,
     "sourceId": 6924328,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4018032,
     "sourceId": 6990722,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4018042,
     "sourceId": 6990734,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4018819,
     "sourceId": 6991952,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4023338,
     "sourceId": 6998859,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 151583600,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
